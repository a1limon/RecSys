{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "import gzip\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### Just the first 10000 reviews\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parse(\"data/train_Category.json.gz\"))[:10000]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userID': 'u74382925',\n",
       " 'genre': 'Adventure',\n",
       " 'early_access': False,\n",
       " 'reviewID': 'r75487422',\n",
       " 'hours': 4.1,\n",
       " 'text': 'Short Review:\\nA good starting chapter for this series, despite the main character being annoying (for now) and a short length. The story is good and actually gets more interesting. Worth the try.\\nLong Review:\\nBlackwell Legacy is the first on the series of (supposedly) 5 games that talks about the main protagonist, Rosangela Blackwell, as being a so called Medium, and in this first chapter we get to know how her story will start and how she will meet her adventure companion Joey...and really, that\\'s really all for for now and that\\'s not a bad thing, because in a way this game wants to show how hard her new job is, and that she cannot escape her destiny as a medium.\\nMy biggest complain for this chapter, except the short length, it\\'s the main protagonist being a \"bit\" too annoying to be likeable, and most of her dialogues will always be about complaining or just be annoyed. Understandable, sure, but lighten\\' up will ya!?\\nHowever, considering that in the next installments she will be much more likeable and kind of interesting, I\\'d say give it a shot and see if you like it: if you hate this first game, you might like the next, or can always stop here.\\nI recommend it.',\n",
       " 'genreID': 3,\n",
       " 'date': '2014-02-07'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    d['text'] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     bigram = list(ngrams(token, 2)) \n",
    "    text = \" \".join(d['text'].splitlines())\n",
    "    bigram = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    for b in bigram:\n",
    "        bigrams[b] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many unique bigrams are there amongst the reviews? List the 5 most-frequently-occurring bigrams along with their number of occurrences in the corpus (1 mark).\n",
    "<!-- #### 256,326 unique bigrams amongst the 10000 reviews -->\n",
    "#### 257,124 unique bigrams amongst the 10000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257124"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 most frequently occuring bigrams with their number of occurences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('this', 'game'), 4438),\n",
       " (('the', 'game'), 4249),\n",
       " (('of', 'the'), 3356),\n",
       " (('if', 'you'), 2018),\n",
       " (('in', 'the'), 2017)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigrams.items(),key=lambda v: v[1],reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostCommon =sorted(bigrams.items(),key=lambda v: v[1],reverse=True)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The code provided performs least squares using the 1000 most common unigrams. Adapt it to use the 1000 most common bigrams and report the MSE obtained using the new predictor (use bigrams only, i.e., not unigrams+bigrams) (1 mark). Note that the code performs regularized regression with a regularization parameter of 1.0. The prediction target should be log2 (hours + 1) (i.e., our transformed time variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_words = [b[0] for b in mostCommon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramId = dict(zip(bigram_words, range(len(bigram_words))))\n",
    "bigramSet = set(bigram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_bigram(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     bigram_words = list(ngrams(token, 2)) \n",
    "#     t = t.lower() # lowercase string\n",
    "#     t = [c for c in t] # non-punct characters\n",
    "#     t = ''.join(t) # convert back to string\n",
    "#     words = t.strip().split() # tokenizes \n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    \n",
    "    for w in bigram_words:\n",
    "        if not (w in bigramSet): continue\n",
    "        feat[bigramId[w]] += 1\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature_bigram(d) for d in data]\n",
    "y = [math.log(d['hours'] + 1,2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) \n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  4.399483733665732\n"
     ]
    }
   ],
   "source": [
    "print(\"mse: \", MSE(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Repeat the above experiment using unigrams and bigrams, still considering the 1000 most common. That is, your model will still use 1000 features (plus an offset), but those 1000 features will be some combination of unigrams and bigrams. Report the MSE obtained using the new predictor (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1)) \n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    for u in unigram:\n",
    "        unigrams[u] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get 1000 most common unigrams and bigrams from corpus (10,000 reviews)\n",
    "mostCommonUni =sorted(unigrams.items(),key=lambda v: v[1],reverse=True)[:1000]\n",
    "mostCommonBi =sorted(bigrams.items(),key=lambda v: v[1],reverse=True)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "for i in mostCommonUni:\n",
    "    combined.append(i)\n",
    "\n",
    "for i in mostCommonBi:\n",
    "    combined.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = sorted(combined, key = lambda x: x[1], reverse = True)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 34211),\n",
       " ('and', 19392),\n",
       " ('a', 18791),\n",
       " ('to', 18077),\n",
       " ('game', 15043),\n",
       " ('of', 14095),\n",
       " ('is', 13000),\n",
       " ('you', 12735),\n",
       " ('i', 12204),\n",
       " ('it', 11824),\n",
       " ('this', 9548),\n",
       " ('in', 8274),\n",
       " ('that', 7060),\n",
       " ('for', 6526),\n",
       " ('but', 6321),\n",
       " ('with', 5586),\n",
       " ('its', 5144),\n",
       " ('are', 4849),\n",
       " ('on', 4559),\n",
       " (('this', 'game'), 4438)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_words = [u[0] for u in mostCommonUni]\n",
    "bigram_words = [b[0] for b in mostCommonBi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_words = [w[0] for w in combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramId = dict(zip(unigram_words, range(len(unigram_words))))\n",
    "unigramSet = set(unigram_words)\n",
    "bigramId = dict(zip(bigram_words, range(len(bigram_words))))\n",
    "bigramSet = set(bigram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_bi_and_uni(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "    \n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    unigram_words = text.strip().split()\n",
    " \n",
    "   \n",
    "#     for w in bigram_words:\n",
    "#         if not (w in bigramSet): continue\n",
    "#         feat[bigramId[w]] += 1\n",
    "        \n",
    "#     for w in unigram_words:\n",
    "#         if not (w in unigramSet): continue\n",
    "#         feat[unigramId[w]] += 1\n",
    "    \n",
    "    for w in combined_words:\n",
    "        if not (w in bigramSet): continue\n",
    "        feat[bigramId[w]] += 1\n",
    "        \n",
    "    for w in combined_words:\n",
    "        if not (w in unigramSet): continue\n",
    "        feat[unigramId[w]] += 1\n",
    "        \n",
    "        \n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature_bi_and_uni(d) for d in data]\n",
    "y = [math.log(d['hours'] + 1,2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) \n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  5.242478901430268\n"
     ]
    }
   ],
   "source": [
    "print(\"mse: \", MSE(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note the increase in MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another idea I had was to instead create a random combination of unigrams and bigrams as a feature, of course each option has a .5 chance of being incorporated as a feature so I wouldn't expect the model's performance to differ too much but i wanted to observe the results nonetheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_bi_and_uni(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     bigram_words = list(ngrams(token, 2))\n",
    "#     unigram_words = list(ngrams(token, 1))\n",
    " \n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    unigram_words = text.strip().split()\n",
    "    \n",
    "    uni_or_bi = random.choice(['uni', 'bi'])\n",
    "    if uni_or_bi == 'bi':\n",
    "        for w in bigram_words:\n",
    "            if not (w in bigramSet): continue\n",
    "            feat[bigramId[w]] += 1\n",
    "    else:  \n",
    "        for w in unigram_words:\n",
    "            if not (w in unigramSet): continue\n",
    "            feat[unigramId[w]] += 1\n",
    "        \n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature_bi_and_uni(d) for d in data]\n",
    "y = [math.log(d['hours'] + 1,2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) \n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  4.403605155664077\n"
     ]
    }
   ],
   "source": [
    "print(\"mse: \", MSE(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note the increase in mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the inverse document frequency of the words ‘destiny’, ‘annoying’, ‘likeable’, ‘chapter’, and ‘interesting’? What are their tf-idf scores in review ID r75487422 (using log base 10, unigrams only, following the first definition of tf-idf given in the slides) (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "docFreq = defaultdict(set)\n",
    "for d in data:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1)) \n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    \n",
    "    for u in unigram:\n",
    "        docFreq[u].add(d['reviewID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqueReviews = set()\n",
    "# totalRevs = 0\n",
    "# for d in data:\n",
    "#     if d['reviewID'] in uniqueReviews: continue\n",
    "#     uniqueReviews.add(d['reviewID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idf-destiny: 3.3979400086720375\n",
      "idf-annoying: 1.8386319977650252\n",
      "idf-likeable: 3.0969100130080562\n",
      "idf-chapter: 2.221848749616356\n",
      "idf-interesting: 1.3585258894959005\n"
     ]
    }
   ],
   "source": [
    "idf_destiny = np.log10( len(data)/ len(docFreq['destiny']))\n",
    "idf_annoying = np.log10( len(data)/ len(docFreq['annoying']))\n",
    "idf_likeable = np.log10(len(data) / len(docFreq['likeable']))\n",
    "idf_chapter = np.log10( len(data)/ len(docFreq['chapter']))\n",
    "idf_interesting = np.log10( len(data)/ len(docFreq['interesting']))\n",
    "print(\"idf-destiny:\",idf_destiny )\n",
    "print(\"idf-annoying:\",idf_annoying)\n",
    "print(\"idf-likeable:\",idf_likeable)\n",
    "print(\"idf-chapter:\",idf_chapter)\n",
    "print(\"idf-interesting:\",idf_interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r75487422 = data[0]['text']\n",
    "tf = defaultdict(int)\n",
    "for d in data:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1)) \n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    for u in unigram:\n",
    "        tf[u] +=1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_idf-destiny: 3.3979400086720375\n",
      "tf_idf-annoying: 3.6772639955300503\n",
      "tf_idf-likeable: 6.1938200260161125\n",
      "tf_idf-chapter: 6.665546248849068\n",
      "tf_idf-interesting: 2.717051778991801\n"
     ]
    }
   ],
   "source": [
    "tf_idf_destiny = tf['destiny'] * idf_destiny\n",
    "tf_idf_annoying = tf['annoying'] * idf_annoying\n",
    "tf_idf_likeable = tf['likeable'] * idf_likeable\n",
    "tf_idf_chapter = tf['chapter'] * idf_chapter\n",
    "tf_idf_interesting = tf['interesting'] * idf_interesting\n",
    "print(\"tf_idf-destiny:\",tf_idf_destiny )\n",
    "print(\"tf_idf-annoying:\",tf_idf_annoying)\n",
    "print(\"tf_idf-likeable:\",tf_idf_likeable)\n",
    "print(\"tf_idf-chapter:\",tf_idf_chapter)\n",
    "print(\"tf_idf-interesting:\",tf_idf_interesting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adapt your unigram model to use the tfidf scores of words, rather than a bag-of-words representation. That is, rather than your features containing the word counts for the 1000 most common unigrams, it should contain tfidf scores for the 1000 most common unigrams. Report the MSE of this new model (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFreq = defaultdict(set)\n",
    "for d in data:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1)) \n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    for u in unigram:\n",
    "        docFreq[u].add(d['reviewID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = defaultdict(int)\n",
    "for d in data:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1)) \n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    for u in unigram:\n",
    "        tf[u] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostCommonUni =sorted(tf.items(),key=lambda v: v[1],reverse=True)[:1000]\n",
    "unigram_words = [u[0] for u in mostCommonUni]\n",
    "unigramId = dict(zip(unigram_words, range(len(unigram_words))))\n",
    "unigramSet = set(unigram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_uni(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     unigram_words = list(ngrams(token, 1))\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram_words= text.strip().split()\n",
    "    \n",
    "    for u in unigram_words:\n",
    "        if not (u in unigramSet): continue\n",
    "        tf_idf_word = np.log10(len(data)/ len(docFreq[u])) * tf[u]\n",
    "        feat[unigramId[u]] = tf_idf_word\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature_uni(d) for d in data]\n",
    "y = [math.log(d['hours'] + 1,2) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) \n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  4.106655150599012\n"
     ]
    }
   ],
   "source": [
    "print(\"mse: \", MSE(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which other review has the highest cosine similarity compared to review ID r75487422, in terms of their tf-idf representations (considering unigrams only). Provide the reviewID, or the text of the review (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userID': 'u74382925',\n",
       " 'genre': 'Adventure',\n",
       " 'early_access': False,\n",
       " 'reviewID': 'r75487422',\n",
       " 'hours': 4.1,\n",
       " 'text': 'short review\\na good starting chapter for this series despite the main character being annoying for now and a short length the story is good and actually gets more interesting worth the try\\nlong review\\nblackwell legacy is the first on the series of supposedly 5 games that talks about the main protagonist rosangela blackwell as being a so called medium and in this first chapter we get to know how her story will start and how she will meet her adventure companion joeyand really thats really all for for now and thats not a bad thing because in a way this game wants to show how hard her new job is and that she cannot escape her destiny as a medium\\nmy biggest complain for this chapter except the short length its the main protagonist being a bit too annoying to be likeable and most of her dialogues will always be about complaining or just be annoyed understandable sure but lighten up will ya\\nhowever considering that in the next installments she will be much more likeable and kind of interesting id say give it a shot and see if you like it if you hate this first game you might like the next or can always stop here\\ni recommend it',\n",
       " 'genreID': 3,\n",
       " 'date': '2014-02-07'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSim(s1, s2):\n",
    "    numer = np.dot(s1,s2) # intersection of sets / dot product between sets\n",
    "    denom = np.linalg.norm(s1) * np.linalg.norm(s2)# magnitude of s1 * magnitude of s2\n",
    "    dot_product = np.dot(a, b)\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_review = data[0]\n",
    "cosinesims = []\n",
    "Xfirst = feature_uni(first_review)\n",
    "for d in data[1:]:\n",
    "    review_i = feature_uni(d)\n",
    "    cosinesims.append((d['reviewID'],cosineSim(Xfirst, review_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('r89686923', 0.9020892284292362)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cosinesims,key=lambda tup: tup[1], reverse = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Implement a validation pipeline for this same data, by randomly shuffling the data, using 10,000 reviews for training, another 10,000 for validation, and another 10,000 for testing.1 Consider regularization parameters in the range {0.01, 0.1, 1, 10, 100}, and report MSEs on the test set for the model that performs best on the validation set. Using this pipeline, compare the following alternatives in terms of their performance (all using 1,000 dimensional word features):\n",
    "- Unigrams vs. bigrams\n",
    "- Removing punctuation vs. preserving it. The model that preserves punctuation should treat punctuation characters as separate words, e.g. “Amazing!” would become [‘amazing’, ‘!’]\n",
    "- tfidf scores vs. word counts\n",
    "\n",
    "### In total you should compare 2 × 2 × 2 × 5 = 40 models (8 models and 5 regularization parameters), andproduce a table comparing their performance (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = list(parse(\"data/train_Category.json.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d for d in full_data]\n",
    "y = [math.log(d['hours'] + 1,2) for d in full_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "Xy = list(zip(X,y))\n",
    "random.shuffle(Xy)\n",
    "X = np.array([d[0] for d in Xy])\n",
    "y = np.array([d[1] for d in Xy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[:10000]\n",
    "Xvalid = X[10000:20000]\n",
    "Xtest = X[20000:30000]\n",
    "\n",
    "ytrain = y[:10000]\n",
    "yvalid = y[10000:20000]\n",
    "ytest = y[20000:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [.01, .1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###from piazza\n",
    "\n",
    "#Unigrams, keep punc, tfidf\n",
    "\n",
    "#unigrams, discard punc, tfidf\n",
    "\n",
    "#bigrams, keep punc, tfidf\n",
    "\n",
    "#bigrams, discard punc, tfidf\n",
    "\n",
    "#unigrams, keep punc, counts\n",
    "\n",
    "#unigrams, discard punc, counts\n",
    "\n",
    "#bigrams, keep punc, counts\n",
    "\n",
    "#bigrams, discard punc, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigrams, keep punc, tfidf\n",
    "#training data\n",
    "unigrams = defaultdict(int)\n",
    "for d in Xtrain:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1))\n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    for u in unigram:\n",
    "        unigrams[u] += 1\n",
    "\n",
    "#1000 most common from training set\n",
    "mostCommonUni =sorted(unigrams.items(),key=lambda v: v[1],reverse=True)[:1000]\n",
    "unigram_words = [u[0] for u in mostCommonUni]\n",
    "unigramId = dict(zip(unigram_words, range(len(unigram_words))))\n",
    "unigramSet = set(unigram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docFreq and tf\n",
    "#training data\n",
    "docFreq = defaultdict(set)\n",
    "for d in Xtrain:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     unigram = list(ngrams(token, 1)) \n",
    "    t = d['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram = text.strip().split()\n",
    "    for u in unigram:\n",
    "        docFreq[u].add(d['reviewID'])\n",
    "\n",
    "#term freq\n",
    "tf = unigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_uni_punc_tfidf(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "#     t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     unigram_words = list(ngrams(token, 1))\n",
    "    t = datum['text']\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram_words = text.strip().split()\n",
    "    \n",
    "    for u in unigram_words:\n",
    "        if not (u in unigramSet): continue\n",
    "        tf_idf_word = np.log10(len(Xtrain)/ len(docFreq[u])) * tf[u]\n",
    "        feat[unigramId[u]] = tf_idf_word\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_1 = [feature_uni_punc_tfidf(d) for d in Xtrain]\n",
    "Xvalid_1 = [feature_uni_punc_tfidf(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigrams, discard punc, tfidf\n",
    "def feature_uni_nopunc_tfidf(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    t = datum['text']\n",
    "    t = ''.join([c for c in t.lower() if not c in punctuation])\n",
    "    \n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram_words = text.strip().split()\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     unigram_words = list(ngrams(token, 1))\n",
    "    \n",
    "    for u in unigram_words:\n",
    "        if not (u in unigramSet): continue\n",
    "        tf_idf_word = np.log10(len(Xtrain)/ len(docFreq[u])) * tf[u]\n",
    "        feat[unigramId[u]] = tf_idf_word\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_2 = [feature_uni_nopunc_tfidf(d) for d in Xtrain]\n",
    "Xvalid_2 = [feature_uni_nopunc_tfidf(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigrams, keep punc, counts\n",
    "def feature_uni_punc_wc(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     unigram_words = list(ngrams(token, 1))\n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram_words = text.strip().split()\n",
    "    \n",
    "    for u in unigram_words:\n",
    "        if not (u in unigramSet): continue\n",
    "        feat[unigramId[u]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_3 = [feature_uni_punc_wc(d) for d in Xtrain]\n",
    "Xvalid_3 = [feature_uni_punc_wc(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigrams, discard punc, counts\n",
    "def feature_uni_nopunc_wc(datum):\n",
    "    feat = [0]*len(unigramSet)\n",
    "    t = datum['text']\n",
    "    t = ''.join([c for c in t.lower() if not c in punctuation])\n",
    "    \n",
    "    text = \" \".join(t.splitlines())\n",
    "    unigram_words = text.strip().split()\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     unigram_words = list(ngrams(token, 1))\n",
    "    for u in unigram_words:\n",
    "        if not (u in unigramSet): continue\n",
    "        feat[unigramId[u]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_4 = [feature_uni_nopunc_wc(d) for d in Xtrain]\n",
    "Xvalid_4 = [feature_uni_nopunc_wc(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start of bigram models\n",
    "bigrams = defaultdict(int)\n",
    "\n",
    "for d in Xtrain:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     bigram = list(ngrams(token, 2)) \n",
    "    text = \" \".join(d['text'].splitlines())\n",
    "    bigram = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    for b in bigram:\n",
    "        bigrams[b] += 1\n",
    "        \n",
    "#1000 most common from training set\n",
    "mostCommonBi =sorted(bigrams.items(),key=lambda v: v[1],reverse=True)[:1000]\n",
    "bigram_words = [u[0] for u in mostCommonBi]\n",
    "bigramId = dict(zip(bigram_words, range(len(bigram_words))))\n",
    "bigramSet = set(bigram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docFreq and tf\n",
    "#training data\n",
    "docFreq = defaultdict(set)\n",
    "for d in Xtrain:\n",
    "#     token = nltk.word_tokenize(d['text'])\n",
    "#     bigram = list(ngrams(token, 2)) \n",
    "    text = \" \".join(d['text'].splitlines())\n",
    "    bigram = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    for b in bigram:\n",
    "        docFreq[b].add(d['reviewID'])\n",
    "\n",
    "#term freq\n",
    "tf = bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams, keep punc, tfidf\n",
    "def feature_bi_punc_tfidf(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     bigram_words = list(ngrams(token, 2))\n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    \n",
    "    for b in bigram_words:\n",
    "        if not (b in bigramSet): continue\n",
    "        tf_idf_word = np.log10(len(Xtrain)/ len(docFreq[b])) * tf[b]\n",
    "        feat[bigramId[b]] = tf_idf_word\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_5 = [feature_bi_punc_tfidf(d) for d in Xtrain]\n",
    "Xvalid_5 = [feature_bi_punc_tfidf(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams, discard punc, tfidf\n",
    "def feature_bi_nopunc_tfidf(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     bigram_words = list(ngrams(token, 2))\n",
    "    t = ''.join([c for c in t.lower() if not c in punctuation])\n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    \n",
    "    for b in bigram_words:\n",
    "        if not (b in bigramSet): continue\n",
    "        tf_idf_word = np.log10(len(Xtrain)/ len(docFreq[b])) * tf[b]\n",
    "        feat[bigramId[b]] = tf_idf_word\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_6 = [feature_bi_nopunc_tfidf(d) for d in Xtrain]\n",
    "Xvalid_6 = [feature_bi_nopunc_tfidf(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams, keep punc, counts\n",
    "def feature_bi_punc_wc(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     bigram_words = list(ngrams(token, 2))\n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    \n",
    "    for b in bigram_words:\n",
    "        if not (b in bigramSet): continue\n",
    "        feat[bigramId[b]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_7 = [feature_bi_punc_wc(d) for d in Xtrain]\n",
    "Xvalid_7 = [feature_bi_punc_wc(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams, discard punc, counts\n",
    "def feature_bi_nopunc_wc(datum):\n",
    "    feat = [0]*len(bigramSet)\n",
    "    t = datum['text']\n",
    "\n",
    "#     token = nltk.word_tokenize(t)\n",
    "#     bigram_words = list(ngrams(token, 2))\n",
    "\n",
    "    t = ''.join([c for c in t.lower() if not c in punctuation])\n",
    "    text = \" \".join(t.splitlines())\n",
    "    bigram_words = [b for b in zip(text.split(\" \")[:-1], text.split(\" \")[1:])]\n",
    "    \n",
    "    for b in bigram_words:\n",
    "        if not (b in bigramSet): continue\n",
    "        feat[bigramId[b]] += 1\n",
    "\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_8 = [feature_bi_nopunc_wc(d) for d in Xtrain]\n",
    "Xvalid_8 = [feature_bi_nopunc_wc(d) for d in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "to_fit = [Xtrain_1, Xtrain_2, Xtrain_3, Xtrain_4, Xtrain_5, Xtrain_6, Xtrain_7, Xtrain_8]\n",
    "to_pred = [Xvalid_1, Xvalid_2, Xvalid_3, Xvalid_4, Xvalid_5, Xvalid_6, Xvalid_7, Xvalid_8]\n",
    "model_performances = []\n",
    "for i in range(len(to_fit)):\n",
    "    for a in A:\n",
    "        clf = linear_model.Ridge(a, fit_intercept=False) \n",
    "        clf.fit(to_fit[i], ytrain)\n",
    "        theta = clf.coef_\n",
    "        predictions = clf.predict(to_pred[i])\n",
    "        model_performances.append(MSE(yvalid, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"unigrams, keep punc, tfidf\",\n",
    "\"unigrams, discard punc, tfidf\",\n",
    "\"unigrams, keep punc, counts\",\n",
    "\"unigrams, discard punc, counts\",\n",
    "\"bigrams, keep punc, tfidf\",\n",
    "\"bigrams, discard punc, tfidf\",\n",
    "\"bigrams, keep punc, counts\",\n",
    "\"bigrams, discard punc, counts\"]\n",
    "\n",
    "index_names = []\n",
    "for model in model_names:\n",
    "    for a in A:\n",
    "        index_names.append((model,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(index_names, names=['model','regularization param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>regularization param</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">unigrams, keep punc, tfidf</th>\n",
       "      <th>0.01</th>\n",
       "      <td>5.215339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>5.215344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.215392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.215917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.224640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">unigrams, discard punc, tfidf</th>\n",
       "      <th>0.01</th>\n",
       "      <td>4.982110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>4.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>4.982173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>4.982780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>4.992304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">unigrams, keep punc, counts</th>\n",
       "      <th>0.01</th>\n",
       "      <td>6.108231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>6.104438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>6.070248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.854864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.329262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">unigrams, discard punc, counts</th>\n",
       "      <th>0.01</th>\n",
       "      <td>5.435183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>5.434333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.426033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.358437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.141136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bigrams, keep punc, tfidf</th>\n",
       "      <th>0.01</th>\n",
       "      <td>5.565673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>5.565676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.565711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.566079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.571945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bigrams, discard punc, tfidf</th>\n",
       "      <th>0.01</th>\n",
       "      <td>5.376637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>5.376641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.376683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.377123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.383752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bigrams, keep punc, counts</th>\n",
       "      <th>0.01</th>\n",
       "      <td>5.806254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>5.803601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.777180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.581628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.230566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bigrams, discard punc, counts</th>\n",
       "      <th>0.01</th>\n",
       "      <td>5.759028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>5.752778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.713767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>5.497860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>5.147350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          mse\n",
       "model                          regularization param          \n",
       "unigrams, keep punc, tfidf     0.01                  5.215339\n",
       "                               0.10                  5.215344\n",
       "                               1.00                  5.215392\n",
       "                               10.00                 5.215917\n",
       "                               100.00                5.224640\n",
       "unigrams, discard punc, tfidf  0.01                  4.982110\n",
       "                               0.10                  4.982116\n",
       "                               1.00                  4.982173\n",
       "                               10.00                 4.982780\n",
       "                               100.00                4.992304\n",
       "unigrams, keep punc, counts    0.01                  6.108231\n",
       "                               0.10                  6.104438\n",
       "                               1.00                  6.070248\n",
       "                               10.00                 5.854864\n",
       "                               100.00                5.329262\n",
       "unigrams, discard punc, counts 0.01                  5.435183\n",
       "                               0.10                  5.434333\n",
       "                               1.00                  5.426033\n",
       "                               10.00                 5.358437\n",
       "                               100.00                5.141136\n",
       "bigrams, keep punc, tfidf      0.01                  5.565673\n",
       "                               0.10                  5.565676\n",
       "                               1.00                  5.565711\n",
       "                               10.00                 5.566079\n",
       "                               100.00                5.571945\n",
       "bigrams, discard punc, tfidf   0.01                  5.376637\n",
       "                               0.10                  5.376641\n",
       "                               1.00                  5.376683\n",
       "                               10.00                 5.377123\n",
       "                               100.00                5.383752\n",
       "bigrams, keep punc, counts     0.01                  5.806254\n",
       "                               0.10                  5.803601\n",
       "                               1.00                  5.777180\n",
       "                               10.00                 5.581628\n",
       "                               100.00                5.230566\n",
       "bigrams, discard punc, counts  0.01                  5.759028\n",
       "                               0.10                  5.752778\n",
       "                               1.00                  5.713767\n",
       "                               10.00                 5.497860\n",
       "                               100.00                5.147350"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = model_performances, index = index, columns = ['mse'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mse    4.98211\n",
       "Name: (unigrams, discard punc, tfidf, 0.01), dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'mse').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ = [feature_uni_nopunc_wc(d) for d in Xtrain]\n",
    "Xtest_ = [feature_uni_nopunc_wc(d) for d in Xtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  4.981581181129463\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(100, fit_intercept=False) \n",
    "clf.fit(Xtrain_, ytrain)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(Xtest_)\n",
    "print(\"mse: \", MSE(ytest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
